{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install pycountry-convert\n#using pycountry-convert in kaggle turned out to be a deliberate scam and it did not work out in my favor\n#used the alternative which is to tweak the dataset in excel manually and added the column for the continent","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#let us start by reading the data using pandas\ndata = pd.read_csv (\"../input/covid19all/train_with_continents.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = pd.read_csv (\"../input/covid19all/train_week_1_ahead.csv\")\ndata2 = pd.read_csv (\"../input/covid19all/train_week_two_data.csv\")\ndata3 = pd.read_csv(\"../input/last-week-with-continents/last week with continents.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''lets look at whether the data is of the same size and shape so that we can append the necessary columns to the\nlatest dataset which is data2\n'''\nprint('the size and shape of the data is:',data.shape,'and',data.size)\nprint('the size and shape of the data1 is:',data1.shape,'and',data1.size)\nprint('the size and shape of the data2 is:',data2.shape,'and',data2.size)\nprint('the size and shape of the data3 is:',data3.shape,'and',data3.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at how our data looks like for the first few rows\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the data 1 which shows the week one after I joined the competition\ndata1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the data 2 which shows the week two after I joined the competition\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets get the information we want to know about the whole data\ndisplay(data3.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''looking at the above data2 we can see that the date column comes out as an object(string) lets change that for sth \nthat is going to be easily used during EDA\n'''\n#creating a copy of some part of the dataframe\n#data3['date'] = data3['Date'].copy()\nfrom datetime import datetime\n#data2['Date'] = pd.to_datetime(data2['Date'], format = '%m/%d/%Y')\ndata3['Date converted'] = pd.to_datetime(data3['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets see if the data.dtype for the date column has changed\ndisplay(data3.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at the unique names for the columns and from there also the unique values so as to drop unwanted data\nlist(data3.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the repeated columns which are the last two\n#repeated_columns_for_dropping = data[['Territory','Date']]\n#data = data.drop(repeated_columns_for_dropping,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look at the train data description to better understand the data\ndata3.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Territories: \", data['Territory'].nunique())\nprint(\"Number of Territories: \", data1['Territory'].nunique())\nprint(\"Number of Territories: \", data2['Territory'].nunique())\nprint(\"Number of Territories: \", data3['Territory'].nunique())\nprint(\"Dates go from day\", min(data['Date']), \"to day\", max(data['Date']), \", a total of\", data['Date'].nunique(), \"days\")\nprint(\"Dates go from day\", min(data1['Date']), \"to day\", max(data1['Date']), \", a total of\", data1['Date'].nunique(), \"days\")\nprint(\"Dates go from day\", min(data2['Date']), \"to day\", max(data2['Date']), \", a total of\", data2['Date'].nunique(), \"days\")\nprint(\"Dates go from day\", min(data3['Date']), \"to day\", max(data3['Date']), \", a total of\", data3['Date'].nunique(), \"days\")\n#our data has no states\n#print(\"Countries with Province/State informed: \", data[data['Province/State'].isna()==False]['Country/Region'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''#let us look at these territories just to make sure that each stands on its own\nwe actually do not need thia cell so we can do away with it\nprint(data['Territory'].nunique())\nprint(data2['Territory'].nunique())\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from the above data we can see that each country appears only once \n#lets see the number of entries per Territory\ndata['Territory'].value_counts()\ndata1['Territory'].value_counts()\ndata2['Territory'].value_counts()\ndata3['Territory'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''# produces Pandas Series\ndata.groupby('month')['duration'].sum() \n# Produces Pandas DataFrame\ndata.groupby('month')[['duration']].sum()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check the number of deaths and infected confirmed cases by using plots\n#importing the necessary dependency\nimport matplotlib.pyplot as plt\n#for week one\n\nconfirmed_total_date = data.groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date = data.groupby(['Date']).agg({'target':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week  two\nconfirmed_total_date = data1.groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date = data1.groupby(['Date']).agg({'target':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week three \nconfirmed_total_date = data2.groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date = data2.groupby(['Date']).agg({'target':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n\n#for the last week \nconfirmed_total_date = data3.groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date = data3.groupby(['Date']).agg({'target':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we know that the virus originated from china so we can use this to compare with the China graph for both the confirmed cases against the deaths and check if the graphs flow the same remembering that during some time china changed how it considered whether somebody was considered positive (11/03/2020).This may be registered as a spike and considering other policies that are put in place that may likely affect the number of cases of the infected people.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets draw the curve excluding china\n#for week one\nconfirmed_total_date_noChina = data[data['Territory']!='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_noChina = data[data['Territory']!='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week two \nconfirmed_total_date_noChina = data1[data1['Territory']!='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_noChina = data1[data1['Territory']!='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week 3\nconfirmed_total_date_noChina = data2[data2['Territory']!='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_noChina = data2[data2['Territory']!='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n\n#for last week\nconfirmed_total_date_noChina = data3[data3['Territory']!='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_noChina = data3[data3['Territory']!='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Without China we should be getting a smoother curve as which more or less looks like the SIR model for epidemiology where there is a steep rise then a gentle drop in the number of cases but remember that unlike other countries that can learn from China,China had no prior warning of the contagion."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for week one\nconfirmed_total_date_China = data[data['Territory']=='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_China = data[data['Territory']=='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n#for week two\nconfirmed_total_date_China = data1[data1['Territory']=='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_China = data1[data1['Territory']=='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week 3\nconfirmed_total_date_China = data2[data2['Territory']=='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_China = data2[data2['Territory']=='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for last week of the prediction\nconfirmed_total_date_China = data3[data3['Territory']=='China'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_China = data3[data3['Territory']=='China'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for week one\nconfirmed_total_date_kenya = data[data['Territory']=='Kenya'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_kenya = data[data['Territory']=='Kenya'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_kenya = confirmed_total_date_kenya.join(fatalities_total_date_kenya)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_kenya.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_kenya.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week two\nconfirmed_total_date_kenya = data1[data1['Territory']=='Kenya'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_kenya = data1[data1['Territory']=='Kenya'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_kenya = confirmed_total_date_kenya.join(fatalities_total_date_kenya)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_kenya.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_kenya.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for week 3\nconfirmed_total_date_kenya = data2[data2['Territory']=='Kenya'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_kenya = data2[data2['Territory']=='Kenya'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_kenya = confirmed_total_date_kenya.join(fatalities_total_date_kenya)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_kenya.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_kenya.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)\n\n#for last week of prediction\nconfirmed_total_date_kenya = data3[data3['Territory']=='Kenya'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_kenya = data3[data3['Territory']=='Kenya'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_kenya = confirmed_total_date_kenya.join(fatalities_total_date_kenya)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date_kenya.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=10)\nax1.set_ylabel(\"Number of cases\", size=10)\nax1.set_xlabel(\"Date\", size=10)\nfatalities_total_date_kenya.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=10)\nax2.set_ylabel(\"Number of cases\", size=10)\nax2.set_xlabel(\"Date\", size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking at the worst hit countries as of now for week one\n#Italy\nconfirmed_total_date_Italy = data[data['Territory']=='Italy'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Italy = data[data['Territory']=='Italy'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#Spain\nconfirmed_total_date_Spain = data[data['Territory']=='Spain'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Spain = data[data['Territory']=='Spain'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n#Autralia\nconfirmed_total_date_Australia = data[data['Territory']=='Australia'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Australia = data[data['Territory']=='Australia'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n#Singapore\nconfirmed_total_date_Singapore = data[data['Territory']=='Singapore'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Singapore = data[data['Territory']=='Singapore'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n#South Korea\n#Singapore\nconfirmed_total_date_SouthKorea = data[data['Territory']=='Republic of Korea'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_SouthKorea = data[data['Territory']=='Republic of Korea'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_SouthKorea = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_Australia.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\n'''plt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')\n'''\nplt.subplot(2, 2, 4)\ntotal_date_SouthKorea.plot(ax=plt.gca(), title='SouthKorea')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking at the worst hit countries as of now for week 2\n#Italy\nconfirmed_total_date_Italy = data1[data1['Territory']=='Italy'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Italy = data1[data1['Territory']=='Italy'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#Spain\nconfirmed_total_date_Spain = data1[data1['Territory']=='Spain'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Spain = data1[data1['Territory']=='Spain'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n#Autralia\nconfirmed_total_date_Australia = data1[data1['Territory']=='Australia'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Australia = data1[data1['Territory']=='Australia'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n#Singapore\nconfirmed_total_date_Singapore = data1[data1['Territory']=='Singapore'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Singapore = data1[data1['Territory']=='Singapore'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n#South Korea\n#Singapore\nconfirmed_total_date_SouthKorea = data1[data1['Territory']=='Republic of Korea'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_SouthKorea = data1[data1['Territory']=='Republic of Korea'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_SouthKorea = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_Australia.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\n'''plt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')\n'''\nplt.subplot(2, 2, 4)\ntotal_date_SouthKorea.plot(ax=plt.gca(), title='SouthKorea')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking at the worst hit countries as of now for week 3\n#Italy\nconfirmed_total_date_Italy = data2[data2['Territory']=='Italy'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Italy = data2[data2['Territory']=='Italy'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#Spain\nconfirmed_total_date_Spain = data2[data2['Territory']=='Spain'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Spain = data2[data2['Territory']=='Spain'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n#Autralia\nconfirmed_total_date_Australia = data2[data2['Territory']=='Australia'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Australia = data2[data2['Territory']=='Australia'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n#Singapore\nconfirmed_total_date_Singapore = data2[data2['Territory']=='Singapore'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Singapore = data2[data2['Territory']=='Singapore'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n#South Korea\n#Singapore\nconfirmed_total_date_SouthKorea = data2[data2['Territory']=='Republic of Korea'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_SouthKorea = data2[data2['Territory']=='Republic of Korea'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_SouthKorea = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_Australia.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\n'''plt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')\n'''\nplt.subplot(2, 2, 4)\ntotal_date_SouthKorea.plot(ax=plt.gca(), title='SouthKorea')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking at the worst hit countries as of now for last week of the prediction \n#Italy\nconfirmed_total_date_Italy = data3[data3['Territory']=='Italy'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Italy = data3[data3['Territory']=='Italy'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#Spain\nconfirmed_total_date_Spain = data3[data3['Territory']=='Spain'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Spain = data3[data3['Territory']=='Spain'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n#Autralia\nconfirmed_total_date_Australia = data3[data3['Territory']=='Australia'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Australia = data3[data3['Territory']=='Australia'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n#Singapore\nconfirmed_total_date_Singapore = data3[data3['Territory']=='Singapore'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_Singapore = data3[data3['Territory']=='Singapore'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n#South Korea\n#Singapore\nconfirmed_total_date_SouthKorea = data3[data3['Territory']=='Republic of Korea'].groupby(['Date']).agg({'cases':['sum']})\nfatalities_total_date_SouthKorea = data3[data3['Territory']=='Republic of Korea'].groupby(['Date']).agg({'target':['sum']})\ntotal_date_SouthKorea = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_Australia.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\n'''plt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')\n'''\nplt.subplot(2, 2, 4)\ntotal_date_SouthKorea.plot(ax=plt.gca(), title='SouthKorea')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#what type of data can we deduce from the given data\n#we can get the mortality rate in the countries as of the beginning of the beginning and we will compare with other weeks\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''calculating the difference between cases and target that will help in getting mortality rate in different weeks\nand seeing among them there may be recoveries'''\ndata['diff']=data['cases'] - data['target']\n#week one diff\ndata1['diff']=data1['cases'] - data1['target']\n#week two diff\ndata2['diff']=data2['cases'] - data2['target']\n#week last diff\ndata3['diff']=data3['cases'] - data3['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets look through the three developed diff columns and see whether their are any missing values\n#for the first dataset\nprint(data.isna().any())\nprint(data.isna().sum())\n#for the second dataset\nprint(data1.isna().any())\nprint(data1.isna().sum())\n#for the third dataset\nprint(data2.isna().any())\nprint(data2.isna().sum())\n#for the last dataset\nprint(data3.isna().any())\nprint(data3.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''#calculating the increase in the number of cases between the weeks\ndata['weekoneincrease']=data1['cases'] - data['cases']\ndata['weektwoincreasefromweekone']=data2['cases'] - data1['cases']\nthis is no necessary just calculate the values in a descending order\n'''\n#calculate the rise in cases by subtracting the previous value of a row with another \n#data1[\"risen cases\"] = data1[\"cases\"].diff(-1)\n#we use the +ve notation since we want o subtract one from the next\ndata3[\"risen cases\"] = data3[\"cases\"].diff(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing the first value with a zero\ndata3[\"risen cases\"]=data3['risen cases'].replace(np.nan, 0.00, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking whether there are any zero values in our latest dataset\nprint(data3.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets also add a column of the rise in deaths to our latest data set\ndata3[\"risen targets daily\"] = data3[\"target\"].diff(1)\n#change the value of the first loc[0] to a 0\ndata3['risen targets daily'] = data3['risen targets daily'].replace(np.nan, 0.00, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking whether the difference column has been created\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating the mortality rates of different Territories rounded off to two decimal places\n#last week mortality rate\ndata3['mortality rate last week'] = round((data3['target']/data3['cases']) * 100,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing the Nans in the mortality rate with 0.00\ndata3['mortality rate last week'] = data3['mortality rate last week'].replace(np.nan, 0.00, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking at the data type for the various columns that we have\nprint(data3.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the values for mortality rate\nprint(\"mortality rates in last week: \", data3['mortality rate last week'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#finding out the rise in mortality rate per day in each of the territories\ndata3[\"mortality rate rise per day\"] = data3[\"mortality rate last week\"].diff(1)\n#change the value of the first loc[0] to a 0\ndata3['mortality rate rise per day'] = data3['mortality rate rise per day'].replace(np.nan, 0.00, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''#lets group the respective Territories to their Continents this may help in organizing per R0\nimport pycountry_convert as pc\n\ncountry_code = pc.country_name_to_country_alpha2(\"China\", cn_name_format=\"default\")\nprint(country_code)\ncontinent_name = pc.country_alpha2_to_continent_code(country_code)\nprint(continent_name)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''the next part is to check the modal split of the individual continents but there was lack of data for the various\ncontinents especially Africa so lets look at sth that we have data on which is which countries have put up stringent\nmeasures and with those we can use the R0 as a little less than others where people still move freely\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfor places with high laws on covid we use 3,medium we use 2 and low we use 1 and very low 0\nadapted from https://www.weforum.org/agenda/2020/03/coronavirus-this-is-how-the-world-is-responding/ and\nhttps://www.vox.com/science-and-health/2020/3/22/21189889/coronavirus-covid-19-pandemic-response-south-korea-phillipines-italy-nicaragua-senegal-hong-kong\nhttps://www.nation.co.ke/news/How-countries-are-battling-coronavirus/1056-5502012-147wgeoz/index.html\nhttp://www.xinhuanet.com/english/2020-03/16/c_138883650.htm\n'''\ndef label_race (row):\n    if row['Territory'] == 'Republic of Korea (the)' :\n        return 3\n    if row['Territory'] == 'United States of America (the)' :\n        return 2\n    if row['Territory'] == 'Philippines (the)':\n        return 1\n    if row['Territory']  == 'Nicaragua':\n        return 0\n    if row['Territory'] == 'Italy':\n        return 1\n    if row['Territory'] == 'Senegal':\n        return 3\n    if row['Territory'] == 'Singapore':\n        return 3\n    if row['Territory'] == 'Tunisia':\n        return 2\n    if row['Territory'] == 'Kenya':\n        return 2\n    if row['Territory'] == 'France':\n        return 2\n    if row['Territory'] == 'Iran (Islamic Republic of)':\n        return 1\n    if row['Territory'] == 'Germany':\n        return 2\n    if row['Territory'] == 'Switzerland':\n        return 2\n    if row['Territory'] == 'Austria':\n        return 1\n    if row['Territory'] == 'China':\n        return 3\n    if row['Territory'] == 'Japan':\n        return 2\n    if row['Territory'] == 'Saudi Arabia':\n        return 3\n    if row['Territory'] == 'Egypt':\n        return 3\n    if row['Territory'] == 'United Kingdom of Great Britain and Northern Ireland (the)':\n        return 2\n    if row['Territory'] == 'South Africa':\n        return 2\n    if row['Territory'] == 'Uganda':\n        return 1\n    if row['Territory'] == 'Argentina':\n        return 2\n    if row['Territory'] == 'Serbia':\n        return 3\n    if row['Territory'] == 'Czechia':\n        return 2\n    if row['Territory'] == 'Mexico':\n        return 1\n    if row['Territory'] == 'Iraq':\n        return 2\n    if row['Territory'] == 'Astralia':\n        return 2\n    return 0\n#data.apply (lambda row: label_race(row), axis=1)\ndata3['Stringent'] = data3.apply (lambda row: label_race(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking to see if the values for the Stringent stuck\nprint(\"Number of unique values for the Stringent column: \", data3['Stringent'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for the data types of all columns\nprint(data3.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of unique values for the Continent column: \", data3['Continent'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''looking at the epidemic a country is only as efficient as its health system and am assuming that the \ncountries economic strength has a relationship with its health system'''\n'''https://en.wikipedia.org/wiki/List_of_continents_by_GDP_(nominal) -->link to list of continents by their gdp\nas of 2019 in billions of us dollars'''\ndef label_economy (row):\n    if row['Continent'] == 'Asia' :\n        return 31580\n    if row['Continent'] == 'Europe' :\n        return 21790\n    if row['Continent'] == 'Africa':\n        return 2450\n    if row['Continent']  == 'North America':\n        return 24430\n    if row['Continent'] == 'South America':\n        return 3640\n    if row['Continent'] == 'Oceania':\n        return 1630\n    if row['Continent'] == 'Europe and Asia':\n        return 26685\n    return 0\n#data.apply (lambda row: label_race(row), axis=1)\ndata3['continents economy'] = data3.apply (lambda row: label_economy(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking out the data\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for the unique values of the continents economy \nprint(\"Number of unique values for the Continent economy column: \", data3['continents economy'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''lets look at the countries that have had an encounter with another corona virus epidemic and thus it is \nlikely that the countries would have measures put in place to deal with another such virus\nthis is adapted from: https://www.who.int/csr/sars/country/table2004_04_21/en/'''\ndef label_sars (row):\n    if row['Territory'] == 'Australia' :\n        return 6\n    if row['Territory'] == 'Canada' :\n        return 251\n    if row['Territory'] == 'China':\n        return 532700\n    if row['Territory']  == 'Taiwan':\n        return 34600\n    if row['Territory'] == 'France':\n        return 7\n    if row['Territory'] == 'Germany':\n        return 9\n    if row['Territory'] == 'India':\n        return 3\n    if row['Territory'] == 'Indonesia':\n        return 2\n    if row['Territory'] == 'Italy':\n        return 4\n    if row['Territory'] == 'Kuwait':\n        return 1\n    if row['Territory'] == 'Malaysia':\n        return 5\n    if row['Territory'] == 'Mongolia':\n        return 9\n    if row['Territory'] == 'New Zealand':\n        return 1\n    if row['Territory'] == 'Philippines (the)':\n        return 14\n    if row['Territory'] == 'United Kingdom of Great Britain and Northern Ireland (the)':\n        return 5\n    if row['Territory'] == 'Russian Federation (the)':\n        return 1\n    if row['Territory'] == 'Singapore':\n        return 238\n    if row['Territory'] == 'South Africa':\n        return 1\n    if row['Territory'] == 'Spain':\n        return 1\n    if row['Territory'] == 'Sweden':\n        return 5\n    if row['Territory'] == 'Switzerland':\n        return 1\n    if row['Territory'] == 'Thailand':\n        return 9\n    if row['Territory'] == 'United States of America (the)':\n        return 27\n    if row['Territory'] == 'Viet Nam':\n        return 63\n    return 0\n#data.apply (lambda row: label_race(row), axis=1)\ndata3['countries sars infections'] = data3.apply (lambda row: label_sars(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets view the data head\ndata3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data3.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''pre processing and this will be used to make sure that you convert all the object columns into sth that can be \nused to train the model and in this we are going to be using xgboost\nfor the conversion from categorical to interger we are going to use a function in case we need to re use\nfunction at a later time\n\nfrom sklearn.preprocessing import OrdinalEncoder\ndef categoricalToInteger(data2):\n    #Define Ordinal Encoder Model\n    oe = OrdinalEncoder()\n    data2[['Territory X Date','Territory','Continent']] = oe.fit_transform(data2.loc[:,['Territory X Date','Territory','Continent']])\n    return data2\n#apply the function\ndata2 = categoricalToInteger(data2)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with the MERS epidemic it is seen to have only affected Saudi Arabia being the focal point of the disease and all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''we know that the more data we have the better our model will actually become so we can use this to our \nadvantage and split the date column to have more data from it\n'''\nimport datetime as dt\ndef create_features_from_date(data3):\n    data3['day'] = data3['Date converted'].dt.day\n    data3['month'] = data3['Date converted'].dt.month\n    data3['dayofweek'] = data3['Date converted'].dt.dayofweek\n    data3['dayofyear'] = data3['Date converted'].dt.dayofyear\n    data3['quarter'] = data3['Date converted'].dt.quarter\n    data3['weekofyear'] = data3['Date converted'].dt.weekofyear\n    return data3\n#apply the function\ndata3 = create_features_from_date(data3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying out something lets see how it works with what I already have","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#example when using the time delta function in present time\nfrom datetime import datetime, timedelta  \n# Using current time \nini_time_for_now = datetime.now() \n# printing initial_date \nprint (\"initial_date\", str(ini_time_for_now))  \n# Calculating future dates \n# for two years \nfuture_date_after_2yrs = ini_time_for_now + \\ \n                        timedelta(days = 730) \n  \nfuture_date_after_2days = ini_time_for_now + \\ \n                         timedelta(days = 2) \n  \n# printing calculated future_dates \nprint('future_date_after_2yrs:', str(future_date_after_2yrs)) \nprint('future_date_after_2days:', str(future_date_after_2days))\n\n#another example of time delta usage in calculating the difference\n\nfrom datetime import datetime, timedelta \n  \n# Using current time \nini_time_for_now = datetime.now() \n  \n# printing initial_date \nprint (\"initial_date\", str(ini_time_for_now)) \n  \n# Some another datetime \nnew_final_time = ini_time_for_now + \\timedelta(days = 2) \n  \n# printing new final_date \nprint (\"new_final_time\", str(new_final_time)) \n  \n  \n# printing calculated past_dates \nprint('Time difference:', str(new_final_time - \\ini_time_for_now)) \n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the necessary dependencies on top of the ones I had already imported \nimport matplotlib.pyplot as plt\n#time delta is mainly used for time manipulation and looking at the fact that we are gooing to be using future forecast\nfrom datetime import datetime, timedelta,date\n#pandas profiling is a level up from the normal describe and info that give basic analytics\nimport pandas_profiling \nfrom pandas_profiling import ProfileReport\nimport seaborn as sns\nfrom sklearn.metrics import mean_absolute_error as mae\n\n#importing machine learning libraries\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as metrics\nfrom sklearn.cluster import KMeans\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\n\n#importing regressors\nfrom xgboost.sklearn import XGBRegressor\n#from catboost import CatBoostRegressor\nfrom numpy import sqrt \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\n#from catboost import Pool\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n#ignoring warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pandas_profiling import ProfileReport\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#allowing visualizastions inline\n%matplotlib inline\n\n#Pipeline and encoders\n#from sklearn.compose import columnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3withoutcases = data3.drop([\"Territory X Date\" ],axis=1)\n\ndata3withoutcases.fillna(0,inplace=True)\nter_enc = {}\n\nregions = sorted(data3withoutcases['Territory'].unique())\nfor r in regions:\n    x = data3withoutcases[data3withoutcases.Territory == r]['mortality rate last week']\n    ter_enc[r] = x.values[len(x.values)-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3withoutcases.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#An all encoder for the datas3,validation set and test set on creating them\ndef AllEncoder(train,validation,test ,entype,cols_index):\n\n  encoder = None\n  if entype == \"l\": \n    lab_enc = LabelEncoder()\n    for col_index in cols_index :\n      data3[col_index] = lab_enc.fit_transform(data3[col_index])\n      validation[col_index] = lab_enc.transform(validation[col_index])\n      test[col_index] = lab_enc.transform(test[col_index])        \n\n  elif entype == \"h\" :\n     oh_enc = OneHotEncoder(handle_unknown = 'ignore' , sparse = False)\n     OH_cols_data3 = pd.DataFrame(oh_enc.fit_transform(data3[cols_index]))\n     OH_cols_valid = pd.DataFrame(oh_enc.transform(validation[cols_index]))\n     OH_cols_test = pd.DataFrame(oh_enc.transform(test[cols_index]))\n     OH_cols_data3.index = data3.index\n     OH_cols_valid.index = validation.index\n     OH_cols_test.index = test.index\n     numerical_data3 = data3.drop(cols_index , axis = 1)\n     numerical_valid = validation.drop(cols_index , axis = 1)\n     numerical_test = test.drop(cols_index , axis = 1)\n     data3 = pd.concat([numerical_data3 , OH_cols_data3], axis = 1 ) \n     validation = pd.concat([numerical_valid , OH_cols_valid] , axis = 1)\n     test = pd.concat([numerical_test , OH_cols_test] , axis = 1)\n  elif entype == \"m\" :\n       \n    #mean encoding\n    from sklearn.model_selection import KFold\n    kf = KFold(n_splits = 5 , shuffle = False )\n    for data3_index , val_index in kf.split(df) :\n        X_data3 , X_val = df.iloc[data3_index] , df.iloc[val_index]\n        df.loc[val_index,'Terr_mean_encoded'] = X_val['Territory'].map(X_data3.groupby('Territory')['target'].mean())\n    df['Terr_mean_encoded'].fillna(df.target.mean(), inplace=True) # filling the na with globel mean\n    ter_enc = {'Territory':df['Territory'] , 'Terr_mean_encoded' : df['Terr_mean_encoded']}\n    test['Terr_mean_encoded'] = df['Territory'].map()\n\n\n  else : \n      print(\"use h , l or m for entype\")\n    \n    \n  return  data3,validation,test\n\n\ndef handle_bad_cols(trainx,val_test):\n  object_cols = [col for col in trainx.columns if trainx[col].dtype == 'object'] \n  good_label_cols = [col for col in object_cols if set(trainx[col]) == set(val_test[col]) ]\n  bad_label_cols = list( set(object_cols) - set(good_label_cols) )\n  for i in bad_label_cols:\n    most = trainx[i].value_counts().index[0]\n    labels = trainx[i].unique()\n    val_test[i] = val_test[i].apply(lambda x : x if x in labels else most)\n  return val_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you have to use strptime to convert a string into date\nfrom datetime import datetime\nlastweekindex = data3withoutcases[data3withoutcases['Date converted'] >= datetime.strptime('2020-4-1','%Y-%m-%d')  ].index\nvalidate = data3withoutcases.iloc[lastweekindex]\ndata3withoutcases = data3withoutcases.drop(lastweekindex) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nsubmission = pd.read_csv(\"../input/covid-submission-sample/SampleSubmission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add Separate Region and Date columns\nsubmission['Territory'] = submission['Region X Date'].apply(lambda x: x.split(' X ')[0])\nsubmission['Date'] = submission['Region X Date'].apply(lambda x: datetime(\n        int(\"20\"+x.split(' X ')[1].split(\"/\")[2]),\n        int(x.split(' X ')[1].split(\"/\")[0]),\n        int(x.split(' X ')[1].split(\"/\")[1])\n        ))\n\nsubmissionclean = submission.drop([\"Region X Date\"],axis=1)\n\n#submission['week_num'] = submission.Date.apply(lambda d: datetime(d).strftime(\"%V\"))\n#submission = submission.merge(train.drop(['month','day','Date'],axis = 1) , on ['Territory','week_num']) \n\n#submissionclean[\"year\"] = submissionclean.Date.apply(lambda x : x.year)\nsubmissionclean[\"month\"] = submissionclean.Date.apply(lambda x : x.month)\nsubmissionclean[\"day\"] = submissionclean.Date.apply(lambda x : x.day)\n#submissionclean[\"weekday\"] = submissionclean.Date.apply(lambda x : x.weekday())\nsubmission.drop(\"Date\",axis=1,inplace=True)\n#submissionclean.drop(\"Date\",axis=1,inplace=True)\n#submissionclean['Terr_mean_encoded'] = submissionclean['Territory'].map(ter_enc)\nsubmissionclean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionclean_death = submissionclean.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionclean_death['deathrate'] = submissionclean_death['Territory'].map(ter_enc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionclean_death['cases'] = data3['cases']\nsubmissionclean_death.fillna(0 , inplace = True)\nsubmissionclean_death","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3withoutcases.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cases_enc = {}\n\nregions = sorted(submissionclean_death['Territory'].unique())\nfor r in regions:\n    cases_per_Terr = submissionclean_death[submissionclean_death.Territory == r]['cases']\n    cases_enc[r] = np.max(cases_per_Terr.values)\ncases_enc\n#submissionclean_death[submissionclean_death.Date > datetime(2020,3,23)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissionclean_death['cases'] = submissionclean_death['Territory'].map(cases_enc)\nindex = submissionclean[submissionclean.Date <= data3['Date converted'][len(data3)-1]].target.index\nindex2 = data3[data3['Date converted'] >= submissionclean.Date[0]].target.index \n#timesteps = len(submission.iloc[index].Date.unique())\n#print(len(index),len(index2))\nfor i in range(len(index)):\n#submissionclean.target[index[i]]= train.target[index2[i]]\n  submissionclean_death.cases[index[i]]= data3.cases[index2[i]] \n\nsubmissionclean_death.fillna(0 , inplace = True)  \nsubmissionclean_death","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainwithoutcasesL , validateL , submissioncleanL = AllEncoder(trainwithoutcases,validate,submissionclean,\"l\",[\"Territory\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here is how you create a submission csv for the competition\ndates = pd.date_range(start='2020-03-06', end='2020-06-07', freq='1d')\nids = []\nfor c in sorted(data3['Territory'].unique()):\n  for d in dates:\n    ids.append(c + ' X ' + d.strftime('%m/%d/%y'))\nss = pd.DataFrame({\n    'Territory X Date':ids,\n    'target':0\n})\nss.to_csv('SampleSubmission.csv', index=False)\nss.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}